{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00384495-31a9-496c-a7ab-dc78bbb1ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"..\\..\\data\\processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f0227-137d-437f-819c-5aa1b97c472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# (Optional) Build a simple knowledge graph for reference\n",
    "def build_knowledge_graph(data):\n",
    "    kg = {}\n",
    "    for _, row in data.iterrows():\n",
    "        user = row[\"user_id\"]\n",
    "        movie = row[\"movie_id\"]\n",
    "        if user not in kg:\n",
    "            kg[user] = []\n",
    "        kg[user].append(movie)\n",
    "        if movie not in kg:\n",
    "            kg[movie] = []\n",
    "        kg[movie].append(user)\n",
    "    return kg\n",
    "\n",
    "kg = build_knowledge_graph(data)\n",
    "\n",
    "# Step 3: Prepare train and test data\n",
    "def prepare_train_test_data(data):\n",
    "    train_data, test_data = train_test_split(data, test_size=0.5, random_state=42)\n",
    "    train_users = train_data[\"user_id\"].values\n",
    "    train_movies = train_data[\"movie_id\"].values\n",
    "    train_gender = train_data[\"gender\"].values\n",
    "    train_age = train_data[\"age\"].values\n",
    "    train_occupation = train_data[\"occupation\"].values\n",
    "    train_zip = train_data[\"zip_code\"].values\n",
    "    train_labels = train_data[\"rating\"].values\n",
    "\n",
    "    test_users = test_data[\"user_id\"].values\n",
    "    test_movies = test_data[\"movie_id\"].values\n",
    "    test_gender = test_data[\"gender\"].values\n",
    "    test_age = test_data[\"age\"].values\n",
    "    test_occupation = test_data[\"occupation\"].values\n",
    "    test_zip = test_data[\"zip_code\"].values\n",
    "    test_labels = test_data[\"rating\"].values\n",
    "\n",
    "    return train_users, train_movies, train_gender, train_age, train_occupation, train_zip, train_labels, \\\n",
    "           test_users, test_movies, test_gender, test_age, test_occupation, test_zip, test_labels\n",
    "\n",
    "(train_users, train_movies, train_gender, train_age, train_occupation, train_zip, train_labels,\n",
    " test_users, test_movies, test_gender, test_age, test_occupation, test_zip, test_labels) = prepare_train_test_data(data)\n",
    "\n",
    "# Step 4: Define the KGAT module\n",
    "class KGAT(torch.nn.Module):\n",
    "    def __init__(self, num_entities, embedding_dim, num_relations=1):\n",
    "        super(KGAT, self).__init__()\n",
    "        # Shared entity embeddings for both users and movies\n",
    "        self.entity_embedding = torch.nn.Embedding(num_entities, embedding_dim)\n",
    "        # Relation embedding (assuming one relation, e.g., \"interacts\")\n",
    "        self.relation_embedding = torch.nn.Embedding(num_relations, embedding_dim)\n",
    "        # A simple attention layer to compute weights between movie and relation embeddings\n",
    "        self.attn_linear = torch.nn.Linear(embedding_dim * 2, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        torch.nn.init.xavier_uniform_(self.entity_embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.relation_embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.attn_linear.weight)\n",
    "        \n",
    "    def forward(self, user_ids, movie_ids, num_users):\n",
    "        # Obtain user representations from the shared entity table\n",
    "        user_kgat = self.entity_embedding(user_ids)\n",
    "        # For movies, offset the indices by the number of users\n",
    "        movie_emb = self.entity_embedding(movie_ids + num_users)\n",
    "        # Get the relation embedding (assume relation id = 0)\n",
    "        rel_emb = self.relation_embedding(torch.tensor(0, device=movie_ids.device))\n",
    "        # Expand the relation embedding to match the batch size\n",
    "        rel_emb_expanded = rel_emb.unsqueeze(0).expand(movie_emb.size(0), -1)\n",
    "        # Concatenate movie embedding and relation embedding\n",
    "        attn_input = torch.cat([movie_emb, rel_emb_expanded], dim=1)\n",
    "        # Compute attention weight (a value between 0 and 1)\n",
    "        attn_weight = torch.sigmoid(self.attn_linear(attn_input))\n",
    "        # Compute the final movie representation using the attention weight\n",
    "        movie_kgat = attn_weight * movie_emb + (1 - attn_weight) * rel_emb_expanded\n",
    "        return user_kgat, movie_kgat\n",
    "\n",
    "# Step 5: Define the Full Model with KGAT\n",
    "class FullModel(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        # Collaborative Filtering (CF) embeddings\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = torch.nn.Embedding(num_movies, embedding_dim)\n",
    "        # KGAT module for knowledge graph based representations (entities: users + movies)\n",
    "        self.kgat = KGAT(num_users + num_movies, embedding_dim, num_relations=1)\n",
    "        # Fully connected layers to merge CF embeddings, KGAT embeddings, and additional features\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim * 4 + 4, 128)  # 4 extra features: gender, age, occupation, zip\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, user_ids, movie_ids, gender, age, occupation, zip_code):\n",
    "        # Get CF embeddings from dedicated embedding layers\n",
    "        user_cf = self.user_embedding(user_ids)\n",
    "        movie_cf = self.movie_embedding(movie_ids)\n",
    "        \n",
    "        # Get KGAT embeddings from the KGAT module\n",
    "        user_kgat, movie_kgat = self.kgat(user_ids, movie_ids, self.num_users)\n",
    "        \n",
    "        # Concatenate all embeddings and additional features into one vector\n",
    "        concat = torch.cat([\n",
    "            user_cf, movie_cf, user_kgat, movie_kgat,\n",
    "            gender.unsqueeze(1), age.unsqueeze(1),\n",
    "            occupation.unsqueeze(1), zip_code.unsqueeze(1)\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers for final rating prediction\n",
    "        x = F.relu(self.fc1(concat))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_users = data[\"user_id\"].nunique()\n",
    "num_movies = data[\"movie_id\"].nunique()\n",
    "embedding_dim = 16\n",
    "\n",
    "# Initialize the model, optimizer, and loss criterion\n",
    "model = FullModel(num_users, num_movies, embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Step 6: Convert data to PyTorch tensors\n",
    "train_users = torch.tensor(train_users, dtype=torch.long)\n",
    "train_movies = torch.tensor(train_movies, dtype=torch.long)\n",
    "train_gender = torch.tensor(train_gender, dtype=torch.float)\n",
    "train_age = torch.tensor(train_age, dtype=torch.float)\n",
    "train_occupation = torch.tensor(train_occupation, dtype=torch.float)\n",
    "train_zip = torch.tensor(train_zip, dtype=torch.float)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float)\n",
    "\n",
    "test_users = torch.tensor(test_users, dtype=torch.long)\n",
    "test_movies = torch.tensor(test_movies, dtype=torch.long)\n",
    "test_gender = torch.tensor(test_gender, dtype=torch.float)\n",
    "test_age = torch.tensor(test_age, dtype=torch.float)\n",
    "test_occupation = torch.tensor(test_occupation, dtype=torch.float)\n",
    "test_zip = torch.tensor(test_zip, dtype=torch.float)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TensorDataset(train_users, train_movies, train_gender, train_age, train_occupation, train_zip, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# Step 7: Train the Model\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        user_ids, movie_ids, gender, age, occupation, zip_code, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids, movie_ids, gender, age, occupation, zip_code)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_users, test_movies, test_gender, test_age, test_occupation, test_zip)\n",
    "    test_loss = criterion(test_outputs.squeeze(), test_labels)\n",
    "    print(f\"Test Loss (MSE): {test_loss.item():.4f}\")\n",
    "\n",
    "# Step 9: Get predictions for both correct and flipped genders (for analysis)\n",
    "with torch.no_grad():\n",
    "    predictions_correct = model(test_users, test_movies, test_gender, test_age, test_occupation, test_zip)\n",
    "    flipped_gender = 1 - test_gender  # Flip gender (0 -> 1, 1 -> 0)\n",
    "    predictions_flipped = model(test_users, test_movies, flipped_gender, test_age, test_occupation, test_zip)\n",
    "\n",
    "# Combine predictions with test data into a DataFrame.\n",
    "test_results = pd.DataFrame({\n",
    "    \"user_id\": test_users.numpy(),\n",
    "    \"movie_id\": test_movies.numpy(),\n",
    "    \"actual_rating\": test_labels.numpy(),\n",
    "    \"predicted_rating_correct_gender\": predictions_correct.squeeze().numpy(),\n",
    "    \"predicted_rating_flipped_gender\": predictions_flipped.squeeze().numpy()\n",
    "})\n",
    "\n",
    "# NEW: Function to get top-N recommendations for a particular user from the test dataset\n",
    "def get_top_n_recommendations(user_id, n, results_df):\n",
    "    \"\"\"\n",
    "    Given a user ID and the results DataFrame, return the top-N movie recommendations\n",
    "    based on the predicted rating (using the correct gender predictions).\n",
    "    \"\"\"\n",
    "    # Filter for the specified user\n",
    "    user_results = results_df[results_df[\"user_id\"] == user_id]\n",
    "    \n",
    "    # If no candidates are found, notify and return an empty DataFrame\n",
    "    if user_results.empty:\n",
    "        print(f\"No candidate movies found for user {user_id}.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Sort the candidate movies in descending order by predicted rating\n",
    "    top_n = user_results.sort_values(by=\"predicted_rating_correct_gender\", ascending=False).head(n)\n",
    "    return top_n\n",
    "\n",
    "# Example: Get top 5 movie recommendations for a particular user (e.g. user with encoded id 0)\n",
    "top_movies = get_top_n_recommendations(user_id=0, n=5, results_df=test_results)\n",
    "print(\"Top 5 recommended movies for user 0:\")\n",
    "print(top_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ba55d-486b-40af-9bcb-0ce64529da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(user_id, n, results_df, rating_type='truth'):\n",
    "    \"\"\"\n",
    "    Given a user ID, return the top-N movie recommendations based on the predicted rating.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: Encoded user ID for which recommendations are desired.\n",
    "    - n: Number of top movies to return.\n",
    "    - results_df: DataFrame containing test results with predictions.\n",
    "    - rating_type: 'truth' to use the ground truth (correct gender) predictions,\n",
    "                   'flipped' to use the flipped gender predictions.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with the top-N recommended movies for the specified user.\n",
    "    \"\"\"\n",
    "    # Filter for the specified user\n",
    "    user_results = results_df[results_df[\"user_id\"] == user_id]\n",
    "    \n",
    "    if user_results.empty:\n",
    "        print(f\"No candidate movies found for user {user_id}.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Choose the appropriate prediction column based on rating_type\n",
    "    if rating_type == 'truth':\n",
    "        col = 'predicted_rating_correct_gender'\n",
    "    elif rating_type == 'flipped':\n",
    "        col = 'predicted_rating_flipped_gender'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid rating_type specified. Use 'truth' or 'flipped'.\")\n",
    "    \n",
    "    # Sort candidate movies by the selected predicted rating in descending order and take top n\n",
    "    top_n = user_results.sort_values(by=col, ascending=False).head(n)\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b3945-6ce5-4a51-b561-1e1678f41d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies_truth = get_top_n_recommendations(user_id=193, n=20, results_df=test_results, rating_type='truth')\n",
    "top_movies_flipped = get_top_n_recommendations(user_id=193, n=20, results_df=test_results, rating_type='flipped')\n",
    "\n",
    "print(\"Top 5 recommended movies for user 0 (Ground Truth Gender):\")\n",
    "print(top_movies_truth)\n",
    "\n",
    "print(\"\\nTop 5 recommended movies for user 0 (Flipped Gender):\")\n",
    "print(top_movies_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049f51c-dfd5-4c7f-be66-118c14e9bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Helper function to compute Discounted Cumulative Gain (DCG)\n",
    "def dcg_at_k(relevances, k=None):\n",
    "    \"\"\"Compute DCG for a list of relevance scores.\n",
    "    If k is None, use all elements.\"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    # Compute gains: you can use 2^r - 1 (exponential gain) or simply r.\n",
    "    gains = 2 ** relevances - 1\n",
    "    # Compute discount factors: log2(rank+1) where rank starts at 1\n",
    "    discounts = np.log2(np.arange(2, 2 + len(relevances)))\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "# Function to compute NDCG for one user given a particular prediction column\n",
    "def ndcg_for_user(user_df, predicted_col, k=None):\n",
    "    \"\"\"\n",
    "    Given a user's DataFrame (with actual ratings and predictions),\n",
    "    compute NDCG based on sorting by the predicted column.\n",
    "    \"\"\"\n",
    "    # Sort the user data by predicted rating (descending order)\n",
    "    user_df_sorted = user_df.sort_values(by=predicted_col, ascending=False)\n",
    "    actual_relevances = user_df_sorted[\"actual_rating\"].values\n",
    "    dcg = dcg_at_k(actual_relevances, k)\n",
    "    \n",
    "    # Compute the ideal DCG by sorting actual ratings in descending order\n",
    "    ideal_relevances = np.sort(user_df[\"actual_rating\"].values)[::-1]\n",
    "    idcg = dcg_at_k(ideal_relevances, k)\n",
    "    \n",
    "    # If the ideal DCG is zero, return zero to avoid division by zero.\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Calculate NDCG for each user in the test set\n",
    "user_ndcg = {}\n",
    "for user in test_results_unpopular[\"user_id\"].unique():\n",
    "    user_df = test_results_unpopular[test_results_unpopular[\"user_id\"] == user]\n",
    "    ndcg_correct = ndcg_for_user(user_df, \"predicted_rating_correct_gender\")\n",
    "    ndcg_flipped = ndcg_for_user(user_df, \"predicted_rating_flipped_gender\")\n",
    "    user_ndcg[user] = {\"ndcg_correct\": ndcg_correct, \"ndcg_flipped\": ndcg_flipped}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "ndcg_df = pd.DataFrame.from_dict(user_ndcg, orient=\"index\").reset_index()\n",
    "ndcg_df = ndcg_df.rename(columns={\"index\": \"user_id\"})\n",
    "\n",
    "# Ensure the \"results_top_n\" directory exists\n",
    "output_dir = \"results_top_n\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"per_user_ndcg_scores_KGAT_unpopuler.csv\")\n",
    "\n",
    "# Save the DataFrame to CSV in the results_top_n directory\n",
    "ndcg_df.to_csv(output_file, index=False)\n",
    "print(f\"Per-user NDCG scores saved to {output_file}\")\n",
    "\n",
    "# Optionally, print NDCG for each user to the console\n",
    "print(\"Per-user NDCG scores:\")\n",
    "for user, scores in user_ndcg.items():\n",
    "    print(f\"User {user}: NDCG (ground truth gender) = {scores['ndcg_correct']:.4f}, NDCG (flipped gender) = {scores['ndcg_flipped']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649d71a-a2e3-4a94-a80f-8643b2898200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to compute Discounted Cumulative Gain (DCG)\n",
    "def compute_dcg(relevance_scores):\n",
    "    \"\"\"\n",
    "    Computes DCG given a list of relevance scores.\n",
    "    DCG = sum(rel_i / log2(i + 1)), where rel_i is the rating at position i (1-based index)\n",
    "    \"\"\"\n",
    "    return np.sum((2**relevance_scores - 1) / np.log2(np.arange(1, len(relevance_scores) + 1) + 1))\n",
    "\n",
    "# Function to compute Normalized Discounted Cumulative Gain (NDCG)\n",
    "def compute_ndcg(actual_ratings, predicted_ratings, top_n):\n",
    "    \"\"\"\n",
    "    Computes NDCG for a given set of actual and predicted ratings.\n",
    "    \"\"\"\n",
    "    # Get top-N predicted movie indices (sorted by predicted rating)\n",
    "    top_n_pred_indices = np.argsort(predicted_ratings)[::-1][:top_n]\n",
    "    \n",
    "    # Get top-N actual movie ratings sorted in the ideal order\n",
    "    ideal_ratings = np.sort(actual_ratings)[::-1][:top_n]\n",
    "\n",
    "    # Retrieve the corresponding actual ratings for the predicted top-N movies\n",
    "    predicted_ratings_sorted = actual_ratings[top_n_pred_indices]\n",
    "\n",
    "    # Compute DCG and IDCG\n",
    "    dcg = compute_dcg(predicted_ratings_sorted)\n",
    "    idcg = compute_dcg(ideal_ratings)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Function to evaluate NDCG over all users\n",
    "def evaluate_ndcg(test_results, top_n=10):\n",
    "    \"\"\"\n",
    "    Computes the average NDCG over all users in the test set.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for user_id in test_results[\"user_id\"].unique():\n",
    "        user_results = test_results[test_results[\"user_id\"] == user_id]\n",
    "\n",
    "        # If user has fewer than top_n movies, skip\n",
    "        if len(user_results) < top_n:\n",
    "            continue\n",
    "\n",
    "        actual_ratings = user_results[\"actual_rating\"].values\n",
    "        predicted_ratings = user_results[\"predicted_rating_correct_gender\"].values\n",
    "\n",
    "        ndcg_score = compute_ndcg(actual_ratings, predicted_ratings, top_n)\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "\n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "# Compute and print the NDCG score\n",
    "ndcg_value = evaluate_ndcg(test_results, top_n=10)\n",
    "print(f\"Average NDCG@10: {ndcg_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558fb107-c4dd-4e7f-a289-0f6b1830e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Step 9: Create Popular and Unpopular Movie Test Datasets\n",
    "# -------------------------------\n",
    "\n",
    "# Compute movie popularity based on the number of ratings\n",
    "movie_popularity = data.groupby(\"movie_id\")[\"rating\"].count().reset_index()\n",
    "movie_popularity = movie_popularity.rename(columns={\"rating\": \"num_ratings\"})\n",
    "\n",
    "# Define threshold for popularity (median as the split point)\n",
    "popularity_threshold = movie_popularity[\"num_ratings\"].median()\n",
    "\n",
    "# Identify popular and unpopular movies\n",
    "popular_movies = movie_popularity[movie_popularity[\"num_ratings\"] >= popularity_threshold][\"movie_id\"]\n",
    "unpopular_movies = movie_popularity[movie_popularity[\"num_ratings\"] < popularity_threshold][\"movie_id\"]\n",
    "\n",
    "# Create new test datasets\n",
    "test_results_popular = test_results[test_results[\"movie_id\"].isin(popular_movies)]\n",
    "test_results_unpopular = test_results[test_results[\"movie_id\"].isin(unpopular_movies)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b16b9-3c6e-4a1a-a3cb-ec7ef44a0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0db56f-1516-41f4-99cc-312df0bbc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique users from each test dataset\n",
    "users_existing = test_results[\"user_id\"].unique()\n",
    "users_popular = test_results_popular[\"user_id\"].unique()\n",
    "users_unpopular = test_results_unpopular[\"user_id\"].unique()\n",
    "\n",
    "# Create DataFrames with user information\n",
    "user_info = data[[\"user_id\", \"gender\", \"occupation\", \"zip_code\", \"age\"]].drop_duplicates()\n",
    "\n",
    "# Merge user demographic data with test datasets\n",
    "user_info_existing = user_info[user_info[\"user_id\"].isin(users_existing)]\n",
    "user_info_popular = user_info[user_info[\"user_id\"].isin(users_popular)]\n",
    "user_info_unpopular = user_info[user_info[\"user_id\"].isin(users_unpopular)]\n",
    "\n",
    "# Save to CSV files\n",
    "user_info_existing.to_csv(\"user_info_existing.csv\", index=False)\n",
    "user_info_popular.to_csv(\"user_info_popular.csv\", index=False)\n",
    "user_info_unpopular.to_csv(\"user_info_unpopular.csv\", index=False)\n",
    "\n",
    "print(\"User demographic files saved:\")\n",
    "print(f\"- user_info_existing.csv: {len(user_info_existing)} users\")\n",
    "print(f\"- user_info_popular.csv: {len(user_info_popular)} users\")\n",
    "print(f\"- user_info_unpopular.csv: {len(user_info_unpopular)} users\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a83598-f206-4d5c-b760-ab2f47c1a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_unpopular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538e8dc-46c4-49e1-8062-9328226fbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7871c80-453b-4f10-9fb9-222ee40066d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b03829-a96f-4415-b4ff-4d44cda80e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def reciprocal_rank_at_k(relevances, k=None):\n",
    "    \"\"\"\n",
    "    Compute the reciprocal rank for a list of actual relevance scores.\n",
    "    The first occurrence of the maximum relevance is considered the correct item.\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    max_rel = np.max(relevances)\n",
    "    for idx, rel in enumerate(relevances, start=1):\n",
    "        if rel == max_rel:\n",
    "            return 1.0 / idx\n",
    "    return 0.0\n",
    "\n",
    "def mrr_for_user(user_df, predicted_col, k=None):\n",
    "    \"\"\"\n",
    "    Given a user's DataFrame (with actual ratings and predictions),\n",
    "    compute MRR based on sorting by the predicted column.\n",
    "    \"\"\"\n",
    "    sorted_df = user_df.sort_values(by=predicted_col, ascending=False)\n",
    "    actual_relevances = sorted_df[\"actual_rating\"].values\n",
    "    return reciprocal_rank_at_k(actual_relevances, k)\n",
    "\n",
    "# Calculate MRR for each user using the specified prediction columns\n",
    "user_mrr = {}\n",
    "for user in test_results[\"user_id\"].unique():\n",
    "    user_df = test_results[test_results[\"user_id\"] == user]\n",
    "    mrr_correct = mrr_for_user(user_df, \"predicted_rating_correct_gender\")\n",
    "    mrr_flipped = mrr_for_user(user_df, \"predicted_rating_flipped_gender\")\n",
    "    user_mrr[user] = {\"mrr_correct\": mrr_correct, \"mrr_flipped\": mrr_flipped}\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "mrr_df = pd.DataFrame.from_dict(user_mrr, orient=\"index\").reset_index()\n",
    "mrr_df = mrr_df.rename(columns={\"index\": \"user_id\"})\n",
    "\n",
    "# Ensure the output directory exists and save the results\n",
    "output_dir = \"results_top_n_mrr\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"per_user_mrr_scores_KGAT.csv\")\n",
    "mrr_df.to_csv(output_file, index=False)\n",
    "print(f\"Per-user MRR scores saved to {output_file}\")\n",
    "\n",
    "# Optionally, print MRR for each user to the console\n",
    "for user, scores in user_mrr.items():\n",
    "    print(f\"User {user}: MRR (ground truth) = {scores['mrr_correct']:.4f}, MRR (flipped) = {scores['mrr_flipped']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377ee0c-7c2c-4454-a084-6f12bc0ff9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the genre columns as they appear in your original data\n",
    "genre_columns = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
    "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\",\n",
    "    \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame with unique movie genre information by dropping duplicates\n",
    "movie_genres = data[['movie_id'] + genre_columns].drop_duplicates(subset='movie_id')\n",
    "\n",
    "# Merge the unique movie genres into test_results using movie_id as the key\n",
    "test_results_with_genre = test_results.merge(movie_genres, on='movie_id', how='left')\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886915e-10af-47be-8061-e2b7b2e80ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Helper function to compute Discounted Cumulative Gain (DCG)\n",
    "def dcg_at_k(relevances, k=None):\n",
    "    \"\"\"Compute DCG for a list of relevance scores.\n",
    "    If k is None, use all elements.\"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    relevances = np.array(relevances)[:k]\n",
    "\n",
    "    # Compute gains: you can use 2^r - 1 (exponential gain) or simply r.\n",
    "    gains = 2 ** relevances - 1\n",
    "\n",
    "    # Compute discount factors: log2(rank+1), where rank starts at 1\n",
    "    discounts = np.log2(np.arange(2, 2 + len(relevances)))\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "# Function to compute NDCG for one user given a particular prediction column\n",
    "def ndcg_for_user(user_df, predicted_col, k=None):\n",
    "    \"\"\"\n",
    "    Given a user's DataFrame (with actual ratings and predictions),\n",
    "    compute NDCG based on sorting by the predicted column.\n",
    "    \"\"\"\n",
    "    # Sort by predicted rating in descending order\n",
    "    user_df_sorted = user_df.sort_values(by=predicted_col, ascending=False)\n",
    "    actual_relevances = user_df_sorted[\"actual_rating\"].values\n",
    "    dcg = dcg_at_k(actual_relevances, k)\n",
    "\n",
    "    # Compute the ideal DCG by sorting actual ratings in descending order\n",
    "    ideal_relevances = np.sort(user_df[\"actual_rating\"].values)[::-1]\n",
    "    idcg = dcg_at_k(ideal_relevances, k)\n",
    "\n",
    "    # Avoid division by zero if IDCG is 0\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    " \n",
    "genre_columns = [\n",
    "     \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
    "     \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\",\n",
    "     \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "genre_test_results = {}\n",
    "for genre in genre_columns:\n",
    "     genre_test_results[genre] = test_results_with_genre[test_results_with_genre[genre] == 1]\n",
    "\n",
    "\n",
    "# Directory for saving the results\n",
    "output_dir = \"results_top_n\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each genre and compute per-user NDCG\n",
    "for genre, genre_df in genre_test_results.items():\n",
    "    user_ndcg = {}\n",
    "\n",
    "    # Iterate over each user in this particular genre\n",
    "    for user_id in genre_df[\"user_id\"].unique():\n",
    "        user_df = genre_df[genre_df[\"user_id\"] == user_id]\n",
    "\n",
    "        # Calculate NDCG for correct vs. flipped gender predictions\n",
    "        ndcg_correct = ndcg_for_user(user_df, \"predicted_rating_correct_gender\")\n",
    "        ndcg_flipped = ndcg_for_user(user_df, \"predicted_rating_flipped_gender\")\n",
    "\n",
    "        user_ndcg[user_id] = {\n",
    "            \"ndcg_correct\": ndcg_correct,\n",
    "            \"ndcg_flipped\": ndcg_flipped\n",
    "        }\n",
    "\n",
    "    # Convert user_ndcg to a DataFrame\n",
    "    ndcg_df = pd.DataFrame.from_dict(user_ndcg, orient=\"index\").reset_index()\n",
    "    ndcg_df.rename(columns={\"index\": \"user_id\"}, inplace=True)\n",
    "\n",
    "    # Construct an output filename that includes the genre name\n",
    "    output_dir = \"results_top_n_genre/KGAT\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(\n",
    "        output_dir, f\"per_user_ndcg_scores_KGAT_{genre.lower()}.csv\"\n",
    "    )\n",
    "    ndcg_df.to_csv(output_file, index=False)\n",
    "    print(f\"Per-user NDCG scores saved for '{genre}' to: {output_file}\")\n",
    "\n",
    "    # (Optional) Print some results to the console\n",
    "    print(f\"--- NDCG for {genre} ---\")\n",
    "    for u_id, scores in user_ndcg.items():\n",
    "        print(f\"User {u_id}: \"\n",
    "              f\"NDCG (ground truth gender) = {scores['ndcg_correct']:.4f}, \"\n",
    "              f\"NDCG (flipped gender) = {scores['ndcg_flipped']:.4f}\")\n",
    "    print(\"------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe6d07-16d2-4981-8ac4-92d66b4e93d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
