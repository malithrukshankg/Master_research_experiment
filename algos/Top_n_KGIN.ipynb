{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f23ef78-a6c8-4e6e-b98d-ffe16fd485dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"..\\..\\data\\processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec9a040-ae49-4d96-8180-36e9858b5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9838844537734985\n",
      "Epoch 2, Loss: 1.0685551166534424\n",
      "Epoch 3, Loss: 1.041137933731079\n",
      "Epoch 4, Loss: 0.8254877328872681\n",
      "Epoch 5, Loss: 0.930690586566925\n",
      "Epoch 6, Loss: 1.0330489873886108\n",
      "Epoch 7, Loss: 0.7744256854057312\n",
      "Epoch 8, Loss: 1.0392849445343018\n",
      "Epoch 9, Loss: 0.525600790977478\n",
      "Epoch 10, Loss: 0.7445341944694519\n",
      "Test Loss (MSE): 0.9685\n",
      "Top 5 recommended movies for user 0:\n",
      "       user_id  movie_id  actual_rating  predicted_rating_correct_gender  \\\n",
      "43067        0        58            5.0                         4.914962   \n",
      "21517        0       113            5.0                         4.810675   \n",
      "39409        0        11            5.0                         4.755535   \n",
      "22732        0       133            4.0                         4.734975   \n",
      "48724        0        63            5.0                         4.729453   \n",
      "\n",
      "       predicted_rating_flipped_gender  \n",
      "43067                         5.026143  \n",
      "21517                         4.808550  \n",
      "39409                         4.834196  \n",
      "22732                         4.773809  \n",
      "48724                         4.738761  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Build a simple knowledge graph (kg)\n",
    "# Each entity (user or movie) maps to a list of neighbor entity IDs.\n",
    "# -------------------------------\n",
    "def build_knowledge_graph(data):\n",
    "    kg = {}\n",
    "    for _, row in data.iterrows():\n",
    "        user = row[\"user_id\"]\n",
    "        movie = row[\"movie_id\"]\n",
    "        kg.setdefault(user, []).append(movie)\n",
    "        kg.setdefault(movie, []).append(user)\n",
    "    return kg\n",
    "\n",
    "kg = build_knowledge_graph(data)\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare train and test splits\n",
    "# -------------------------------\n",
    "def prepare_train_test_data(data):\n",
    "    train_data, test_data = train_test_split(data, test_size=0.5, random_state=42)\n",
    "    train_users = train_data[\"user_id\"].values\n",
    "    train_movies = train_data[\"movie_id\"].values\n",
    "    train_gender = train_data[\"gender\"].values\n",
    "    train_age = train_data[\"age\"].values\n",
    "    train_occupation = train_data[\"occupation\"].values\n",
    "    train_zip = train_data[\"zip_code\"].values\n",
    "    train_labels = train_data[\"rating\"].values\n",
    "\n",
    "    test_users = test_data[\"user_id\"].values\n",
    "    test_movies = test_data[\"movie_id\"].values\n",
    "    test_gender = test_data[\"gender\"].values\n",
    "    test_age = test_data[\"age\"].values\n",
    "    test_occupation = test_data[\"occupation\"].values\n",
    "    test_zip = test_data[\"zip_code\"].values\n",
    "    test_labels = test_data[\"rating\"].values\n",
    "\n",
    "    return (train_users, train_movies, train_gender, train_age, train_occupation, train_zip, train_labels,\n",
    "            test_users, test_movies, test_gender, test_age, test_occupation, test_zip, test_labels)\n",
    "\n",
    "(train_users, train_movies, train_gender, train_age, train_occupation, train_zip, train_labels,\n",
    " test_users, test_movies, test_gender, test_age, test_occupation, test_zip, test_labels) = prepare_train_test_data(data)\n",
    "\n",
    "# -------------------------------\n",
    "# New: Define the KGIN module\n",
    "# -------------------------------\n",
    "class KGIN(torch.nn.Module):\n",
    "    def __init__(self, num_entities, embedding_dim, kg, num_neighbors=10):\n",
    "        \"\"\"\n",
    "        KGIN: Knowledge Graph Inductive Network.\n",
    "        This module learns unified entity embeddings and, for each entity,\n",
    "        aggregates neighbor information using an attention mechanism.\n",
    "        \"\"\"\n",
    "        super(KGIN, self).__init__()\n",
    "        self.entity_embedding = torch.nn.Embedding(num_entities, embedding_dim)\n",
    "        self.kg = kg  # dictionary mapping entity -> list of neighbor IDs\n",
    "        self.num_neighbors = num_neighbors\n",
    "        # Attention layer for neighbor aggregation:\n",
    "        self.attn_linear = torch.nn.Linear(embedding_dim * 2, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.entity_embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.attn_linear.weight)\n",
    "    \n",
    "    def aggregate_neighbors(self, entity_ids):\n",
    "        aggregated_embeds = []\n",
    "        for entity in entity_ids:\n",
    "            entity_int = entity.item()\n",
    "            neighbors = self.kg.get(entity_int, [])\n",
    "            if len(neighbors) == 0:\n",
    "                # If no neighbors, use a zero vector.\n",
    "                aggregated_embeds.append(torch.zeros(self.entity_embedding.embedding_dim, device=entity_ids.device))\n",
    "            else:\n",
    "                # Sample up to num_neighbors.\n",
    "                if len(neighbors) > self.num_neighbors:\n",
    "                    sampled = np.random.choice(neighbors, self.num_neighbors, replace=False)\n",
    "                else:\n",
    "                    sampled = neighbors\n",
    "                sampled_tensor = torch.tensor(sampled, dtype=torch.long, device=entity_ids.device)\n",
    "                neighbor_embeds = self.entity_embedding(sampled_tensor)  # (n, embedding_dim)\n",
    "                # Get the current entity's base embedding (repeated to match neighbor count).\n",
    "                entity_embed = self.entity_embedding(entity.unsqueeze(0))  # (1, embedding_dim)\n",
    "                entity_repeated = entity_embed.expand(neighbor_embeds.size(0), -1)\n",
    "                # Concatenate and compute attention scores.\n",
    "                attn_input = torch.cat([entity_repeated, neighbor_embeds], dim=1)  # (n, 2*embedding_dim)\n",
    "                attn_scores = torch.sigmoid(self.attn_linear(attn_input))  # (n, 1)\n",
    "                attn_weights = attn_scores / torch.sum(attn_scores)\n",
    "                # Weighted sum of neighbor embeddings.\n",
    "                agg = torch.sum(attn_weights * neighbor_embeds, dim=0)\n",
    "                aggregated_embeds.append(agg)\n",
    "        return torch.stack(aggregated_embeds)\n",
    "    \n",
    "    def forward(self, entity_ids):\n",
    "        base_embeds = self.entity_embedding(entity_ids)\n",
    "        neighbor_agg = self.aggregate_neighbors(entity_ids)\n",
    "        # Combine the base entity embedding with the aggregated neighbor information.\n",
    "        combined = base_embeds + neighbor_agg\n",
    "        return combined\n",
    "\n",
    "# -------------------------------\n",
    "# Define the Full Model using KGIN\n",
    "# -------------------------------\n",
    "class FullModel(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim, kg):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        # Collaborative Filtering (CF) embeddings for users and movies.\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = torch.nn.Embedding(num_movies, embedding_dim)\n",
    "        # KGIN module for knowledge graph representations.\n",
    "        # The unified entity space covers both users and movies (movies are offset by num_users).\n",
    "        self.kgin = KGIN(num_users + num_movies, embedding_dim, kg, num_neighbors=10)\n",
    "        # Fully connected layers to fuse CF embeddings, KGIN representations, and additional features.\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim * 4 + 4, 128)  # 4 extra features: gender, age, occupation, zip\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, user_ids, movie_ids, gender, age, occupation, zip_code):\n",
    "        # CF embeddings.\n",
    "        user_cf = self.user_embedding(user_ids)\n",
    "        movie_cf = self.movie_embedding(movie_ids)\n",
    "        # KGIN representations.\n",
    "        user_kgin = self.kgin(user_ids)\n",
    "        # For movies, offset indices by num_users.\n",
    "        movie_kgin = self.kgin(movie_ids + self.num_users)\n",
    "        \n",
    "        # Concatenate CF and KGIN embeddings along with additional user features.\n",
    "        concat = torch.cat([\n",
    "            user_cf, movie_cf, user_kgin, movie_kgin,\n",
    "            gender.unsqueeze(1), age.unsqueeze(1),\n",
    "            occupation.unsqueeze(1), zip_code.unsqueeze(1)\n",
    "        ], dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(concat))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# Set model parameters and initialize the KGIN-based model\n",
    "# -------------------------------\n",
    "num_users = data[\"user_id\"].nunique()\n",
    "num_movies = data[\"movie_id\"].nunique()\n",
    "embedding_dim = 16\n",
    "\n",
    "model = FullModel(num_users, num_movies, embedding_dim, kg)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# -------------------------------\n",
    "# Convert data to PyTorch tensors\n",
    "# -------------------------------\n",
    "train_users = torch.tensor(train_users, dtype=torch.long)\n",
    "train_movies = torch.tensor(train_movies, dtype=torch.long)\n",
    "train_gender = torch.tensor(train_gender, dtype=torch.float)\n",
    "train_age = torch.tensor(train_age, dtype=torch.float)\n",
    "train_occupation = torch.tensor(train_occupation, dtype=torch.float)\n",
    "train_zip = torch.tensor(train_zip, dtype=torch.float)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float)\n",
    "\n",
    "test_users = torch.tensor(test_users, dtype=torch.long)\n",
    "test_movies = torch.tensor(test_movies, dtype=torch.long)\n",
    "test_gender = torch.tensor(test_gender, dtype=torch.float)\n",
    "test_age = torch.tensor(test_age, dtype=torch.float)\n",
    "test_occupation = torch.tensor(test_occupation, dtype=torch.float)\n",
    "test_zip = torch.tensor(test_zip, dtype=torch.float)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
    "\n",
    "# -------------------------------\n",
    "# Create DataLoader for training\n",
    "# -------------------------------\n",
    "train_dataset = TensorDataset(train_users, train_movies, train_gender, train_age, train_occupation, train_zip, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Train the Model\n",
    "# -------------------------------\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        user_ids, movie_ids, gender, age, occupation, zip_code, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids, movie_ids, gender, age, occupation, zip_code)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate the Model\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_users, test_movies, test_gender, test_age, test_occupation, test_zip)\n",
    "    test_loss = criterion(test_outputs.squeeze(), test_labels)\n",
    "    print(f\"Test Loss (MSE): {test_loss.item():.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Get predictions for both correct and flipped genders (for analysis)\n",
    "# -------------------------------\n",
    "with torch.no_grad():\n",
    "    predictions_correct = model(test_users, test_movies, test_gender, test_age, test_occupation, test_zip)\n",
    "    flipped_gender = 1 - test_gender  # Flip gender (0 -> 1, 1 -> 0)\n",
    "    predictions_flipped = model(test_users, test_movies, flipped_gender, test_age, test_occupation, test_zip)\n",
    "\n",
    "# Combine predictions with test data into a DataFrame.\n",
    "test_results = pd.DataFrame({\n",
    "    \"user_id\": test_users.numpy(),\n",
    "    \"movie_id\": test_movies.numpy(),\n",
    "    \"actual_rating\": test_labels.numpy(),\n",
    "    \"predicted_rating_correct_gender\": predictions_correct.squeeze().numpy(),\n",
    "    \"predicted_rating_flipped_gender\": predictions_flipped.squeeze().numpy()\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# Function to get top-N recommendations for a particular user\n",
    "# -------------------------------\n",
    "def get_top_n_recommendations(user_id, n, results_df):\n",
    "    user_results = results_df[results_df[\"user_id\"] == user_id]\n",
    "    if user_results.empty:\n",
    "        print(f\"No candidate movies found for user {user_id}.\")\n",
    "        return pd.DataFrame()\n",
    "    top_n = user_results.sort_values(by=\"predicted_rating_correct_gender\", ascending=False).head(n)\n",
    "    return top_n\n",
    "\n",
    "# Example: Get top 5 movie recommendations for user 0\n",
    "top_movies = get_top_n_recommendations(user_id=0, n=5, results_df=test_results)\n",
    "print(\"Top 5 recommended movies for user 0:\")\n",
    "print(top_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc375d0f-722e-4933-b6dd-adde2142a5b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_results_unpopular' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate NDCG for each user in the test set\u001b[39;00m\n\u001b[0;32m     37\u001b[0m user_ndcg \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m test_results_unpopular[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m     39\u001b[0m     user_df \u001b[38;5;241m=\u001b[39m test_results_unpopular[test_results_unpopular[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m user]\n\u001b[0;32m     40\u001b[0m     ndcg_correct \u001b[38;5;241m=\u001b[39m ndcg_for_user(user_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_rating_correct_gender\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_results_unpopular' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Helper function to compute Discounted Cumulative Gain (DCG)\n",
    "def dcg_at_k(relevances, k=None):\n",
    "    \"\"\"Compute DCG for a list of relevance scores.\n",
    "    If k is None, use all elements.\"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    # Compute gains: you can use 2^r - 1 (exponential gain) or simply r.\n",
    "    gains = 2 ** relevances - 1\n",
    "    # Compute discount factors: log2(rank+1) where rank starts at 1\n",
    "    discounts = np.log2(np.arange(2, 2 + len(relevances)))\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "# Function to compute NDCG for one user given a particular prediction column\n",
    "def ndcg_for_user(user_df, predicted_col, k=None):\n",
    "    \"\"\"\n",
    "    Given a user's DataFrame (with actual ratings and predictions),\n",
    "    compute NDCG based on sorting by the predicted column.\n",
    "    \"\"\"\n",
    "    # Sort the user data by predicted rating (descending order)\n",
    "    user_df_sorted = user_df.sort_values(by=predicted_col, ascending=False)\n",
    "    actual_relevances = user_df_sorted[\"actual_rating\"].values\n",
    "    dcg = dcg_at_k(actual_relevances, k)\n",
    "    \n",
    "    # Compute the ideal DCG by sorting actual ratings in descending order\n",
    "    ideal_relevances = np.sort(user_df[\"actual_rating\"].values)[::-1]\n",
    "    idcg = dcg_at_k(ideal_relevances, k)\n",
    "    \n",
    "    # If the ideal DCG is zero, return zero to avoid division by zero.\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Calculate NDCG for each user in the test set\n",
    "user_ndcg = {}\n",
    "for user in test_results_unpopular[\"user_id\"].unique():\n",
    "    user_df = test_results_unpopular[test_results_unpopular[\"user_id\"] == user]\n",
    "    ndcg_correct = ndcg_for_user(user_df, \"predicted_rating_correct_gender\")\n",
    "    ndcg_flipped = ndcg_for_user(user_df, \"predicted_rating_flipped_gender\")\n",
    "    user_ndcg[user] = {\"ndcg_correct\": ndcg_correct, \"ndcg_flipped\": ndcg_flipped}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "ndcg_df = pd.DataFrame.from_dict(user_ndcg, orient=\"index\").reset_index()\n",
    "ndcg_df = ndcg_df.rename(columns={\"index\": \"user_id\"})\n",
    "\n",
    "# Ensure the \"results_top_n\" directory exists\n",
    "output_dir = \"results_top_n\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"per_user_ndcg_scores_KGIN_unpopuler.csv\")\n",
    "\n",
    "# Save the DataFrame to CSV in the results_top_n directory\n",
    "ndcg_df.to_csv(output_file, index=False)\n",
    "print(f\"Per-user NDCG scores saved to {output_file}\")\n",
    "\n",
    "# Optionally, print NDCG for each user to the console\n",
    "print(\"Per-user NDCG scores:\")\n",
    "for user, scores in user_ndcg.items():\n",
    "    print(f\"User {user}: NDCG (ground truth gender) = {scores['ndcg_correct']:.4f}, NDCG (flipped gender) = {scores['ndcg_flipped']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed48d36-36b0-4c99-b769-dcef80ef9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to compute Discounted Cumulative Gain (DCG)\n",
    "def compute_dcg(relevance_scores):\n",
    "    \"\"\"\n",
    "    Computes DCG given a list of relevance scores.\n",
    "    DCG = sum(rel_i / log2(i + 1)), where rel_i is the rating at position i (1-based index)\n",
    "    \"\"\"\n",
    "    return np.sum((2**relevance_scores - 1) / np.log2(np.arange(1, len(relevance_scores) + 1) + 1))\n",
    "\n",
    "# Function to compute Normalized Discounted Cumulative Gain (NDCG)\n",
    "def compute_ndcg(actual_ratings, predicted_ratings, top_n):\n",
    "    \"\"\"\n",
    "    Computes NDCG for a given set of actual and predicted ratings.\n",
    "    \"\"\"\n",
    "    # Get top-N predicted movie indices (sorted by predicted rating)\n",
    "    top_n_pred_indices = np.argsort(predicted_ratings)[::-1][:top_n]\n",
    "    \n",
    "    # Get top-N actual movie ratings sorted in the ideal order\n",
    "    ideal_ratings = np.sort(actual_ratings)[::-1][:top_n]\n",
    "\n",
    "    # Retrieve the corresponding actual ratings for the predicted top-N movies\n",
    "    predicted_ratings_sorted = actual_ratings[top_n_pred_indices]\n",
    "\n",
    "    # Compute DCG and IDCG\n",
    "    dcg = compute_dcg(predicted_ratings_sorted)\n",
    "    idcg = compute_dcg(ideal_ratings)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Function to evaluate NDCG over all users\n",
    "def evaluate_ndcg(test_results, top_n=10):\n",
    "    \"\"\"\n",
    "    Computes the average NDCG over all users in the test set.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for user_id in test_results[\"user_id\"].unique():\n",
    "        user_results = test_results[test_results[\"user_id\"] == user_id]\n",
    "\n",
    "        # If user has fewer than top_n movies, skip\n",
    "        if len(user_results) < top_n:\n",
    "            continue\n",
    "\n",
    "        actual_ratings = user_results[\"actual_rating\"].values\n",
    "        predicted_ratings = user_results[\"predicted_rating_correct_gender\"].values\n",
    "\n",
    "        ndcg_score = compute_ndcg(actual_ratings, predicted_ratings, top_n)\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "\n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "# Compute and print the NDCG score\n",
    "ndcg_value = evaluate_ndcg(test_results, top_n=10)\n",
    "print(f\"Average NDCG@10: {ndcg_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca0300-0db7-4d20-bf6f-f5513c1abf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Step 9: Create Popular and Unpopular Movie Test Datasets\n",
    "# -------------------------------\n",
    "\n",
    "# Compute movie popularity based on the number of ratings\n",
    "movie_popularity = data.groupby(\"movie_id\")[\"rating\"].count().reset_index()\n",
    "movie_popularity = movie_popularity.rename(columns={\"rating\": \"num_ratings\"})\n",
    "\n",
    "# Define threshold for popularity (median as the split point)\n",
    "popularity_threshold = movie_popularity[\"num_ratings\"].median()\n",
    "\n",
    "# Identify popular and unpopular movies\n",
    "popular_movies = movie_popularity[movie_popularity[\"num_ratings\"] >= popularity_threshold][\"movie_id\"]\n",
    "unpopular_movies = movie_popularity[movie_popularity[\"num_ratings\"] < popularity_threshold][\"movie_id\"]\n",
    "\n",
    "# Create new test datasets\n",
    "test_results_popular = test_results[test_results[\"movie_id\"].isin(popular_movies)]\n",
    "test_results_unpopular = test_results[test_results[\"movie_id\"].isin(unpopular_movies)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be596ba-e224-4d6f-ae43-d1418040fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def reciprocal_rank_at_k(relevances, k=None):\n",
    "    \"\"\"\n",
    "    Compute the reciprocal rank for a list of actual relevance scores.\n",
    "    The first occurrence of the maximum relevance is considered the correct item.\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    max_rel = np.max(relevances)\n",
    "    for idx, rel in enumerate(relevances, start=1):\n",
    "        if rel == max_rel:\n",
    "            return 1.0 / idx\n",
    "    return 0.0\n",
    "\n",
    "def mrr_for_user(user_df, predicted_col, k=None):\n",
    "    \"\"\"\n",
    "    Given a user's DataFrame (with actual ratings and predictions),\n",
    "    compute MRR based on sorting by the predicted column.\n",
    "    \"\"\"\n",
    "    sorted_df = user_df.sort_values(by=predicted_col, ascending=False)\n",
    "    actual_relevances = sorted_df[\"actual_rating\"].values\n",
    "    return reciprocal_rank_at_k(actual_relevances, 5)\n",
    "\n",
    "# Calculate MRR for each user using the specified prediction columns\n",
    "user_mrr = {}\n",
    "for user in test_results[\"user_id\"].unique():\n",
    "    user_df = test_results[test_results[\"user_id\"] == user]\n",
    "    mrr_correct = mrr_for_user(user_df, \"predicted_rating_correct_gender\")\n",
    "    mrr_flipped = mrr_for_user(user_df, \"predicted_rating_flipped_gender\")\n",
    "    user_mrr[user] = {\"mrr_correct\": mrr_correct, \"mrr_flipped\": mrr_flipped}\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "mrr_df = pd.DataFrame.from_dict(user_mrr, orient=\"index\").reset_index()\n",
    "mrr_df = mrr_df.rename(columns={\"index\": \"user_id\"})\n",
    "\n",
    "# Ensure the output directory exists and save the results\n",
    "output_dir = \"results_top_n_mrr/five\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"per_user_mrr_scores_KGIN_5.csv\")\n",
    "mrr_df.to_csv(output_file, index=False)\n",
    "print(f\"Per-user MRR scores saved to {output_file}\")\n",
    "\n",
    "# Optionally, print MRR for each user to the console\n",
    "for user, scores in user_mrr.items():\n",
    "    print(f\"User {user}: MRR (ground truth) = {scores['mrr_correct']:.4f}, MRR (flipped) = {scores['mrr_flipped']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab22385-6593-4b34-9744-a66c5df03bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Helper function to compute Discounted Cumulative Gain (DCG)\n",
    "def dcg_at_k(relevances, k=None):\n",
    "    \"\"\"Compute DCG for a list of relevance scores.\n",
    "    If k is None, use all elements.\"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    relevances = np.array(relevances)[:k]\n",
    "\n",
    "    # Compute gains: you can use 2^r - 1 (exponential gain) or simply r.\n",
    "    gains = 2 ** relevances - 1\n",
    "\n",
    "    # Compute discount factors: log2(rank+1), where rank starts at 1\n",
    "    discounts = np.log2(np.arange(2, 2 + len(relevances)))\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "# Function to compute NDCG for one user given a particular prediction column\n",
    "def ndcg_for_user(user_df, predicted_col, k=None):\n",
    "    \"\"\"\n",
    "    Given a user's DataFrame (with actual ratings and predictions),\n",
    "    compute NDCG based on sorting by the predicted column.\n",
    "    \"\"\"\n",
    "    # Sort by predicted rating in descending order\n",
    "    user_df_sorted = user_df.sort_values(by=predicted_col, ascending=False)\n",
    "    actual_relevances = user_df_sorted[\"actual_rating\"].values\n",
    "    dcg = dcg_at_k(actual_relevances, k)\n",
    "\n",
    "    # Compute the ideal DCG by sorting actual ratings in descending order\n",
    "    ideal_relevances = np.sort(user_df[\"actual_rating\"].values)[::-1]\n",
    "    idcg = dcg_at_k(ideal_relevances, k)\n",
    "\n",
    "    # Avoid division by zero if IDCG is 0\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    " \n",
    "genre_columns = [\n",
    "     \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
    "     \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\",\n",
    "     \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "genre_test_results = {}\n",
    "for genre in genre_columns:\n",
    "     genre_test_results[genre] = test_results_with_genre[test_results_with_genre[genre] == 1]\n",
    "\n",
    "\n",
    "# Directory for saving the results\n",
    "output_dir = \"results_top_n\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each genre and compute per-user NDCG\n",
    "for genre, genre_df in genre_test_results.items():\n",
    "    user_ndcg = {}\n",
    "\n",
    "    # Iterate over each user in this particular genre\n",
    "    for user_id in genre_df[\"user_id\"].unique():\n",
    "        user_df = genre_df[genre_df[\"user_id\"] == user_id]\n",
    "\n",
    "        # Calculate NDCG for correct vs. flipped gender predictions\n",
    "        ndcg_correct = ndcg_for_user(user_df, \"predicted_rating_correct_gender\")\n",
    "        ndcg_flipped = ndcg_for_user(user_df, \"predicted_rating_flipped_gender\")\n",
    "\n",
    "        user_ndcg[user_id] = {\n",
    "            \"ndcg_correct\": ndcg_correct,\n",
    "            \"ndcg_flipped\": ndcg_flipped\n",
    "        }\n",
    "\n",
    "    # Convert user_ndcg to a DataFrame\n",
    "    ndcg_df = pd.DataFrame.from_dict(user_ndcg, orient=\"index\").reset_index()\n",
    "    ndcg_df.rename(columns={\"index\": \"user_id\"}, inplace=True)\n",
    "\n",
    "    # Construct an output filename that includes the genre name\n",
    "    output_dir = \"results_top_n_genre/KGIN\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(\n",
    "        output_dir, f\"per_user_ndcg_scores_KGIN_{genre.lower()}.csv\"\n",
    "    )\n",
    "    ndcg_df.to_csv(output_file, index=False)\n",
    "    print(f\"Per-user NDCG scores saved for '{genre}' to: {output_file}\")\n",
    "\n",
    "    # (Optional) Print some results to the console\n",
    "    print(f\"--- NDCG for {genre} ---\")\n",
    "    for u_id, scores in user_ndcg.items():\n",
    "        print(f\"User {u_id}: \"\n",
    "              f\"NDCG (ground truth gender) = {scores['ndcg_correct']:.4f}, \"\n",
    "              f\"NDCG (flipped gender) = {scores['ndcg_flipped']:.4f}\")\n",
    "    print(\"------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9977d958-a821-417f-b185-7b4376d87497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  movie_id  actual_rating  predicted_rating_correct_gender  \\\n",
      "0           57       247            4.0                         4.227108   \n",
      "1          363       324            4.0                         3.359250   \n",
      "2          258       404            3.0                         3.743290   \n",
      "3          497       521            3.0                         3.626331   \n",
      "4          279       101            5.0                         3.517832   \n",
      "...        ...       ...            ...                              ...   \n",
      "49995      932       126            5.0                         3.702552   \n",
      "49996        6       666            5.0                         3.603777   \n",
      "49997      654       448            3.0                         2.632025   \n",
      "49998      607      1182            1.0                         3.066096   \n",
      "49999      273       273            4.0                         4.260599   \n",
      "\n",
      "       predicted_rating_flipped_gender  \n",
      "0                             4.282949  \n",
      "1                             3.488680  \n",
      "2                             3.717937  \n",
      "3                             3.686927  \n",
      "4                             3.397169  \n",
      "...                                ...  \n",
      "49995                         3.730063  \n",
      "49996                         3.679520  \n",
      "49997                         2.647429  \n",
      "49998                         3.090219  \n",
      "49999                         4.167311  \n",
      "\n",
      "[50000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the genre columns as they appear in your original data\n",
    "genre_columns = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
    "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\",\n",
    "    \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame with unique movie genre information by dropping duplicates\n",
    "movie_genres = data[['movie_id'] + genre_columns].drop_duplicates(subset='movie_id')\n",
    "\n",
    "# Merge the unique movie genres into test_results using movie_id as the key\n",
    "test_results_with_genre = test_results.merge(movie_genres, on='movie_id', how='left')\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9c9d4-2ffa-436c-b34d-9220cbe64082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
