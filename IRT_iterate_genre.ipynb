{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2df49de-e262-4db8-82a4-2398e9ec1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing genre: sci-fi\n",
      "Found 7 CSV files for genre 'sci-fi'.\n",
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\algo_1\\per_user_ndcg_scores_algo_1_sci-fi.csv, STS array shape: (699,)\n",
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\algo_2\\per_user_ndcg_scores_algo_2_sci-fi.csv, STS array shape: (699,)\n",
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\CKE\\per_user_ndcg_scores_CKE_sci-fi.csv, STS array shape: (699,)\n",
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\KGAT\\per_user_ndcg_scores_KGAT_sci-fi.csv, STS array shape: (699,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6140\\2071558588.py:95: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  user_ids_array = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\KGCN\\per_user_ndcg_scores_KGCN_sci-fi.csv, STS array shape: (699,)\n",
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\KGIN\\per_user_ndcg_scores_KGIN_sci-fi.csv, STS array shape: (699,)\n",
      "Processed D:\\master_reserch\\data\\results_top_n_genre\\NCFKG\\per_user_ndcg_scores_NCFKG_sci-fi.csv, STS array shape: (699,)\n",
      "Final STS matrix shape for 'sci-fi': (699, 7)\n",
      "Fitting Beta3 model for 'sci-fi'...\n",
      "Model fitting complete for 'sci-fi'.\n",
      "Final loss for 'sci-fi': 0.059869773347893375\n",
      "‚úÖ Processed 'sci-fi': Plot saved at D:\\master_reserch\\data\\plots\\discrimination_difficulty_plot_sci-fi.png, Data saved at D:\\master_reserch\\data\\genre_user_info\\genre_user_info_merged_sci-fi.csv\n",
      "\n",
      "üéâ All genres processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from irt import Beta3\n",
    "\n",
    "# ------------------ 1) Configuration ------------------\n",
    "# List of all genres to process\n",
    "genres = [\n",
    "    \"action\", \"adventure\", \"animation\", \"comedy\", \"crime\", \"documentary\",\n",
    "    \"drama\", \"family\", \"fantasy\", \"history\", \"horror\", \"music\", \"mystery\",\n",
    "    \"romance\", \"sci-fi\", \"thriller\", \"war\", \"western\"\n",
    "]\n",
    "\n",
    "# Base directory containing subfolders (one per algorithm)\n",
    "base_dir = os.path.abspath(\"../data/results_top_n_genre\")\n",
    "\n",
    "# Create directories for saving outputs\n",
    "output_plot_dir = os.path.abspath(\"../data/plots\")\n",
    "output_csv_dir = os.path.abspath(\"../data/genre_user_info\")\n",
    "output_ability_dir = os.path.abspath(\"../data/abilityies\")\n",
    "os.makedirs(output_plot_dir, exist_ok=True)\n",
    "os.makedirs(output_csv_dir, exist_ok=True)\n",
    "os.makedirs(output_ability_dir, exist_ok=True)\n",
    "\n",
    "# ------------------ 2) Function Definitions ------------------\n",
    "def compute_sts_matrix_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file containing columns:\n",
    "      - ndcg_correct\n",
    "      - ndcg_flipped\n",
    "    Computes and returns the STS array using:\n",
    "      STS = 1 - abs(ndcg_correct - ndcg_flipped)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Convert NDCG scores to torch tensors\n",
    "    ndcg_correct = torch.tensor(df[\"ndcg_correct\"].values, dtype=torch.float32)\n",
    "    ndcg_flipped = torch.tensor(df[\"ndcg_flipped\"].values, dtype=torch.float32)\n",
    "\n",
    "    user_ids_array = df[\"user_id\"]\n",
    "    \n",
    "    # Compute STS: 1 - abs(ndcg_correct - ndcg_flipped)\n",
    "    sts_array = 1 - 10 * torch.abs(ndcg_correct - ndcg_flipped)\n",
    "    \n",
    "    return sts_array.numpy(), user_ids_array  # Return as a NumPy array\n",
    "\n",
    "\n",
    "def loss_function(b4, df_matrix):\n",
    "    \"\"\"\n",
    "    Simple loss: mean absolute difference between the predicted P(i,j)\n",
    "    and the actual STS value in df_matrix.\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    for i in range(df_matrix.shape[0]):  # items/users\n",
    "        for j in range(df_matrix.shape[1]):  # respondents/models\n",
    "            pij_predicted = ICC_function(\n",
    "                b4.abilities[j],        # ability of respondent/model j\n",
    "                b4.difficulties[i],     # difficulty of item/user i\n",
    "                b4.discriminations[i]   # discrimination of item/user i\n",
    "            )\n",
    "            # Compare to STS value\n",
    "            res = abs(pij_predicted - df_matrix.iloc[i, j])\n",
    "            loss_list.append(res)\n",
    "    return np.mean(loss_list)\n",
    "\n",
    "\n",
    "def ICC_function(abilities, difficulties, discriminations):\n",
    "    \"\"\"\n",
    "    The specific item characteristic curve (ICC) function used by Beta3.\n",
    "    \"\"\"\n",
    "    a = (1 - abilities) / abilities\n",
    "    b = difficulties / (1 - difficulties)\n",
    "    c = a * b\n",
    "    d = c ** discriminations\n",
    "    return 1 / (d + 1)\n",
    "\n",
    "\n",
    "# ------------------ 3) Process Each Genre ------------------\n",
    "for target_genre in genres:\n",
    "    print(f\"\\nProcessing genre: {target_genre}\")\n",
    "\n",
    "    # ------------------ 4) Build the File Pattern ------------------\n",
    "    pattern = os.path.join(base_dir, \"*\", f\"per_user_ndcg_scores_*_{target_genre.lower()}.csv\")\n",
    "    csv_files = glob.glob(pattern)\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"‚ö†Ô∏è No CSV files found for genre '{target_genre}', skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Found {len(csv_files)} CSV files for genre '{target_genre}'.\")\n",
    "\n",
    "    # ------------------ 5) Compute STS from CSV ------------------\n",
    "    list_of_sts_arrays = []\n",
    "    user_ids_array = pd.Series()\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        sts_array, user_ids_array_prev = compute_sts_matrix_from_csv(csv_file)\n",
    "\n",
    "        if user_ids_array.empty:\n",
    "            user_ids_array = user_ids_array_prev\n",
    "        elif not user_ids_array.equals(user_ids_array_prev):\n",
    "            raise ValueError(f\"User ID mismatch in {csv_file}\")\n",
    "\n",
    "        list_of_sts_arrays.append(sts_array)\n",
    "        print(f\"Processed {csv_file}, STS array shape: {sts_array.shape}\")\n",
    "\n",
    "    # ------------------ 6) Combine STS Arrays into One Matrix ------------------\n",
    "    final_matrix = np.vstack(list_of_sts_arrays).T  # shape: (num_users, num_models)\n",
    "    print(f\"Final STS matrix shape for '{target_genre}': {final_matrix.shape}\")\n",
    "\n",
    "    normalized_df = pd.DataFrame(final_matrix)\n",
    "\n",
    "    # ------------------ 7) Beta3 IRT Pipeline ------------------\n",
    "    subjects = normalized_df.shape[1]  # number of models/respondents\n",
    "    items = normalized_df.shape[0]  # number of users/items\n",
    "\n",
    "    # Initialize and run Beta3\n",
    "    b4 = Beta3(\n",
    "        learning_rate=10,\n",
    "        epochs=5000,\n",
    "        n_respondents=subjects,\n",
    "        n_items=items,\n",
    "        n_workers=-1,\n",
    "        random_seed=1,\n",
    "    )\n",
    "\n",
    "    print(f\"Fitting Beta3 model for '{target_genre}'...\")\n",
    "    b4.fit(normalized_df.values)\n",
    "    print(f\"Model fitting complete for '{target_genre}'.\")\n",
    "\n",
    "    loss = loss_function(b4, normalized_df)\n",
    "    print(f\"Final loss for '{target_genre}': {loss}\")\n",
    "\n",
    "    # ------------------ 8) Load and Merge User Data ------------------\n",
    "    user_ids_ordered = user_ids_array.tolist()  # Extract user IDs in order\n",
    "    user_info = pd.read_csv(os.path.abspath(\"../data/user_info_existing.csv\"))  # Ensure this file contains `user_id, gender`\n",
    "    #gender_map = {\"M\": 0, \"F\": 1}\n",
    "    #user_info[\"gender\"] = user_info[\"gender\"].map(gender_map)\n",
    "\n",
    "    user_beta3_results = pd.DataFrame({\n",
    "        \"user_id\": user_ids_ordered,\n",
    "        \"discrimination\": b4.discriminations,\n",
    "        \"difficulty\": b4.difficulties\n",
    "    })\n",
    "\n",
    "    merged_df = user_beta3_results.merge(user_info, on=\"user_id\", how=\"left\")\n",
    "\n",
    "    # ------------------ 9) Plot Results ------------------\n",
    "    disc_values = np.array(merged_df[\"discrimination\"])\n",
    "    difficulty_values = np.array(merged_df[\"difficulty\"])\n",
    "    user_genders = np.array(merged_df[\"gender\"])\n",
    "    colors = np.where(user_genders == 0, \"red\", \"blue\")  # Male = Red, Female = Blue\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.scatter(disc_values, difficulty_values, c=colors, alpha=0.7)\n",
    "    plt.title(f\"Discrimination vs. Difficulty ({target_genre.capitalize()}, Colored by Gender)\")\n",
    "    plt.xlabel(\"Discrimination\")\n",
    "    plt.ylabel(\"Difficulty\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    import matplotlib.patches as mpatches\n",
    "    red_patch = mpatches.Patch(color=\"red\", label=\"Male\")\n",
    "    blue_patch = mpatches.Patch(color=\"blue\", label=\"Female\")\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "    output_plot_path = os.path.join(output_plot_dir, f\"discrimination_difficulty_plot_{target_genre}.png\")\n",
    "    plt.savefig(output_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------ 10) Save Merged Data ------------------\n",
    "    output_csv_path = os.path.join(output_csv_dir, f\"genre_user_info_merged_{target_genre}.csv\")\n",
    "    merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    output_ability_path = os.path.join(output_ability_dir, f\"ability_{target_genre}.csv\")\n",
    "\n",
    "    df_abilities = pd.DataFrame(b4.abilities)  # Convert NumPy array to DataFrame\n",
    "    df_abilities.to_csv(output_ability_path, index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"‚úÖ Processed '{target_genre}': Plot saved at {output_plot_path}, Data saved at {output_csv_path}\")\n",
    "\n",
    "  \n",
    "\n",
    "print(\"\\nüéâ All genres processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071f17c-ca78-405d-afa9-68cebffe868a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
